{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Masking\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data/data_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(sel,names):\n",
    "  \n",
    "  datamain=sel.query(\"SYMBOL=='%s'\"%(names[0]))\n",
    "  datamain=datamain[[\"DATE\",\"PRICE\"]]\n",
    "  datamain.drop_duplicates(subset=[\"DATE\"], keep='first', inplace=True)\n",
    "  datamain=datamain.sort_values(by=\"DATE\")\n",
    "  s=names[0]+\"_price\"\n",
    "  s2=names[0]+\"_size\"\n",
    "  # datamain[\"DATE\"]=pd.to_datetime(datamain[\"DATE\"])\n",
    "  datamain=datamain.rename(columns={\"PRICE\":s})\n",
    "  # datamain[s] = pd.to_numeric(datamain[\"PRICE\"])\n",
    "  # datamain[s2] = pd.to_numeric(datamain[\"SIZE\"])\n",
    "\n",
    "\n",
    "  for name in names:\n",
    "    if name==names[0]:\n",
    "      continue\n",
    "    data=sel.query(\"SYMBOL=='%s'\"%name)\n",
    "\n",
    "    data=data[[\"DATE\",\"PRICE\"]]\n",
    "    data.drop_duplicates(subset=[\"DATE\"], keep='first', inplace=True)\n",
    "    \n",
    "    # data[\"PRICE\"]=pd.to_datetime(data[\"PRICE\"])\n",
    "    # data[\"Close_\"] = pd.to_numeric(data[\"Close_\"])\n",
    " \n",
    "    data=data.rename(columns={\"PRICE\": \"%s_price\"%name})\n",
    "\n",
    "\n",
    "    datamain=pd.merge(datamain,data,on=\"DATE\", how=\"outer\")\n",
    "  return datamain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=list(set(df[\"SYMBOL\"]))\n",
    "df=transform_data(df,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(A,F,maskf_sub):\n",
    "  sum=0\n",
    "  length=0\n",
    "  for i in range(len(A)):\n",
    "   \n",
    "    if maskf_sub[i]!=0:\n",
    "      sum+=abs(A[i] - F[i]) / abs(A[i])\n",
    "      length+=1\n",
    "  if length>0:\n",
    "    return 100/length*sum\n",
    "  \n",
    "  return 0\n",
    "def smape(A, F,maskf_sub):\n",
    "  sum=0\n",
    "  length=0\n",
    "  for i in range(len(A)):\n",
    "    if maskf_sub[i]!=0:\n",
    "      sum+=2 * np.abs(F[i] - A[i]) / (np.abs(A[i]) + np.abs(F[i]))\n",
    "      length+=1\n",
    "  if length>0:\n",
    "\n",
    "    return 100/length * sum\n",
    "  return 0\n",
    "\n",
    "\n",
    "def get_mask(data):\n",
    "    \"\"\"\n",
    "    data should in the form of pd.df\n",
    "    gen a tenor with 0 and 1 to represent missing data\n",
    "    \"\"\"\n",
    "    mask = ~data.isna().values\n",
    " \n",
    "    mask_tensor = torch.tensor(mask, dtype=torch.float32)\n",
    "    \n",
    "    mask_tensor= mask_tensor.transpose(0,1)\n",
    "    return mask_tensor\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    first_list=[]\n",
    "    for i in data.columns:\n",
    "       \n",
    "        first=data[i].iloc[0]\n",
    "        p=1\n",
    "        \n",
    "        while np.isnan(first):\n",
    "           first=data[i].iloc[p]\n",
    "\n",
    "           p+=1\n",
    "        \n",
    "        data[i]=(data[i])/first\n",
    "        first_list.append(first)   \n",
    "    return data,first_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lstm_run(df,name,ep,j,num_fea):\n",
    "    \"\"\"df is the data in pd.DataFrame\n",
    "    name is the list of columns name to be predicted\n",
    "    ep is the epoch to train\n",
    "    j is the prediction length\"\"\"    \n",
    "    \n",
    "    X = df[name][:-1]\n",
    "    Y = df[name][1:]\n",
    "  \n",
    "\n",
    "    X_norm,X_div =normalize(X) \n",
    "    Y_norm,Y_div =normalize(Y)\n",
    "    Y_test_mask=get_mask(Y_norm)[:,-j:]\n",
    "    X_norm=X_norm.fillna(0)\n",
    "    Y_norm=Y_norm.fillna(0)\n",
    "    X_norm=X_norm.values\n",
    "    Y_norm=Y_norm.values\n",
    "\n",
    "    X_train, Y_train = X_norm[:-j], Y_norm[:-j]\n",
    "    X_test, Y_test = X_norm[-j:], Y_norm[-j:]\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(X_train.shape[2]))  \n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    model.fit(X_train, Y_train, epochs=ep, batch_size=32, validation_data=(X_test, Y_test), verbose=2, shuffle=False)\n",
    "\n",
    "    test_predict = model.predict(X_test)\n",
    "    smpl=[]\n",
    "    mpl=[]\n",
    "    pred=[]\n",
    "    test=[]\n",
    "    pred=test_predict\n",
    "    test=Y_test\n",
    "\n",
    "    Y_test=Y_test[-j:].transpose(1,0)\n",
    "    test_predict=test_predict[-j:].transpose(1,0)\n",
    "    print(Y_test.shape,test_predict.shape)\n",
    "    print(Y_div[0])\n",
    "\n",
    "\n",
    "    for i in range(num_fea):\n",
    "\n",
    "        mp=mape(Y_test[i]*Y_div[i],test_predict[i]*Y_div[i],Y_test_mask[i])\n",
    "        smp=smape(Y_test[i]*Y_div[i],test_predict[i]*Y_div[i],Y_test_mask[i])\n",
    "        pred[:,i]=pred[:,i]*Y_div[i]\n",
    "        test[:,i]=test[:,i]*Y_div[i]\n",
    "        smpl.append(smp)\n",
    "        mpl.append(mp)\n",
    "    return pred,test,mpl,smpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 - 10s - loss: 0.7348 - val_loss: 0.5937 - 10s/epoch - 1s/step\n",
      "Epoch 2/10\n",
      "8/8 - 0s - loss: 0.6813 - val_loss: 0.5447 - 77ms/epoch - 10ms/step\n",
      "Epoch 3/10\n",
      "8/8 - 0s - loss: 0.6273 - val_loss: 0.4937 - 80ms/epoch - 10ms/step\n",
      "Epoch 4/10\n",
      "8/8 - 0s - loss: 0.5805 - val_loss: 0.4536 - 93ms/epoch - 12ms/step\n",
      "Epoch 5/10\n",
      "8/8 - 0s - loss: 0.5367 - val_loss: 0.4178 - 165ms/epoch - 21ms/step\n",
      "Epoch 6/10\n",
      "8/8 - 0s - loss: 0.4906 - val_loss: 0.3757 - 187ms/epoch - 23ms/step\n",
      "Epoch 7/10\n",
      "8/8 - 0s - loss: 0.4409 - val_loss: 0.3289 - 169ms/epoch - 21ms/step\n",
      "Epoch 8/10\n",
      "8/8 - 0s - loss: 0.3863 - val_loss: 0.2771 - 180ms/epoch - 22ms/step\n",
      "Epoch 9/10\n",
      "8/8 - 0s - loss: 0.3259 - val_loss: 0.2212 - 155ms/epoch - 19ms/step\n",
      "Epoch 10/10\n",
      "8/8 - 0s - loss: 0.2774 - val_loss: 0.2085 - 131ms/epoch - 16ms/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "(3, 1) (3, 1)\n",
      "37.16\n"
     ]
    }
   ],
   "source": [
    "ep=10\n",
    "j=1\n",
    "name=df.columns[1:]\n",
    "num_fea=3\n",
    "pred,test,mpl,smpl=lstm_run(df,name,ep,j,num_fea)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= pd.DataFrame({'lstm_mape':mpl,'lstm_smape':smpl})\n",
    "result.to_csv('D:/timeseries/result/temp_2.csv')\n",
    "res2= pd.DataFrame({'name':name,'day1/1_pred':pred[0], 'day1/1_actu':test[0]\n",
    "                       })\n",
    "res2.to_csv('D:/timeseries/result/temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= pd.DataFrame({'lstm_mape':mpl,'lstm_smape':smpl})\n",
    "result.to_csv('D:/timeseries/result/temp_2.csv')\n",
    "res2= pd.DataFrame({'name':name,'day1/7_pred':pred[0], 'day1/7_actu':test[0],'day2/7_pred':pred[1], \n",
    "                    'day2/7_actu':test[1],'day3/7_pred':pred[2], 'day3/7_actu':test[2],'day4/7_pred':pred[3], \n",
    "                    'day4/7_actu':test[3],'day5/7_pred':pred[4], 'day5/7_actu':test[4],'day6/7_pred':pred[5],\n",
    "                      'day6/7_actu':test[5],'day7/7_pred':pred[6], 'day7/7_actu':test[6]\n",
    "                       })\n",
    "res2.to_csv('D:/timeseries/result/temp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
