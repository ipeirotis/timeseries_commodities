{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Masking\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data/data_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(A,F,maskf_sub):\n",
    "  sum=0\n",
    "  length=0\n",
    "  for i in range(len(A)):\n",
    "   \n",
    "    if maskf_sub[i]!=0:\n",
    "      sum+=abs(A[i] - F[i]) / abs(A[i])\n",
    "      length+=1\n",
    "  if length>0:\n",
    "    return 100/length*sum\n",
    "  \n",
    "  return 0\n",
    "def smape(A, F,maskf_sub):\n",
    "  sum=0\n",
    "  length=0\n",
    "  for i in range(len(A)):\n",
    "    if maskf_sub[i]!=0:\n",
    "      sum+=2 * np.abs(F[i] - A[i]) / (np.abs(A[i]) + np.abs(F[i]))\n",
    "      length+=1\n",
    "  if length>0:\n",
    "\n",
    "    return 100/length * sum\n",
    "  return 0\n",
    "\n",
    "\n",
    "def get_mask(data):\n",
    "    \"\"\"\n",
    "    data should in the form of pd.df\n",
    "    gen a tenor with 0 and 1 to represent missing data\n",
    "    \"\"\"\n",
    "    mask = ~data.isna().values\n",
    " \n",
    "    mask_tensor = torch.tensor(mask, dtype=torch.float32)\n",
    "    \n",
    "    mask_tensor= mask_tensor.transpose(0,1)\n",
    "    return mask_tensor\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    first_list=[]\n",
    "    for i in data.columns:\n",
    "       \n",
    "        first=data[i].iloc[0]\n",
    "        p=1\n",
    "        \n",
    "        while np.isnan(first):\n",
    "           first=data[i].iloc[p]\n",
    "\n",
    "           p+=1\n",
    "        \n",
    "        data[i]=(data[i])/first\n",
    "        first_list.append(first)   \n",
    "    return data,first_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lstm_run(df,name,ep,j):\n",
    "    \"\"\"df is the data in pd.DataFrame\n",
    "    name is the list of columns name to be predicted\n",
    "    ep is the epoch to train\n",
    "    j is the prediction length\"\"\"    \n",
    "    \n",
    "    X = df[name][:-1]\n",
    "    Y = df[name][1:]\n",
    "  \n",
    "\n",
    "    X_norm,X_div =normalize(X) \n",
    "    Y_norm,Y_div =normalize(Y)\n",
    "    Y_test_mask=get_mask(Y_norm)[:,-j:]\n",
    "    X_norm=X_norm.fillna(0)\n",
    "    Y_norm=Y_norm.fillna(0)\n",
    "    X_norm=X_norm.values\n",
    "    Y_norm=Y_norm.values\n",
    "\n",
    "    X_train, Y_train = X_norm[:-j], Y_norm[:-j]\n",
    "    X_test, Y_test = X_norm[-j:], Y_norm[-j:]\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(X_train.shape[2]))  \n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    model.fit(X_train, Y_train, epochs=ep, batch_size=32, validation_data=(X_test, Y_test), verbose=2, shuffle=False)\n",
    "\n",
    "    test_predict = model.predict(X_test)\n",
    "    smpl=[]\n",
    "    mpl=[]\n",
    "    pred=[]\n",
    "    test=[]\n",
    "    Y_test=Y_test[-j:].transpose(1,0)\n",
    "    test_predict=test_predict[-j:].transpose(1,0)\n",
    "\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        mp=mape(Y_test[i]*Y_div[i],test_predict[i]*Y_div[i],Y_test_mask[i])\n",
    "        smp=smape(Y_test[i]*Y_div[i],test_predict[i]*Y_div[i],Y_test_mask[i])\n",
    "        pred.append(test_predict[i]*Y_div[i])\n",
    "        test.append(Y_test[i]*Y_div[i])\n",
    "        smpl.append(smp)\n",
    "        mpl.append(mp)\n",
    "    return pred,test,mpl,smpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep=20\n",
    "j=-7\n",
    "name=df.columns[1:]\n",
    "pred,test,mpl,smpl=lstm_run(df,name,ep,j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= pd.DataFrame({'lstm_mape':mpl,'lstm_smape':smpl})\n",
    "result.to_csv('D:/timeseries/result/temp_2.csv')\n",
    "res2= pd.DataFrame({'name':name,'day1/7_pred':pred[0], 'day1/7_actu':test[0], 'day2/7_pred':pred[1], 'day2/7_actu':test[1],\n",
    "                       'day3/7_pred':pred[2], 'day3/7_actu':test[2], 'day4/7_pred':pred[3], 'day4/7_actu':test[3], \n",
    "                       'day5/7_pred':pred[4], 'day5/7_actu':test[4], 'day6/7_pred':pred[5], 'day6/7_actu':test[5],\n",
    "                       'day7/7_pred':pred[6], 'day7/7_actu':test[6]\n",
    "                       })\n",
    "res2.to_csv('D:/timeseries/result/temp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
