{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension for cauchy multiplication not found. Install by going to extensions/cauchy/ and running `python setup.py install`. This should speed up end-to-end training by 10-50%\n",
      "Falling back on slow Cauchy kernel. Install at least one of pykeops or the CUDA extension for efficiency.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import importlib.util\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "module_path = r\"D:/timeseries/package/state-spaces-simple/src/models/sequence/ss/standalone/s4.py\"\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"S4\", module_path)\n",
    "S4 = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(S4)\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('D:/timeseries/data/data_3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    mean_list=[]\n",
    "    std_list=[]\n",
    "    for i in data.columns:\n",
    "   \n",
    "        mean=data[i].mean()\n",
    "       \n",
    "        std=data[i].std()\n",
    "        data[i]=(data[i]-mean)/std\n",
    "        # for j in range(len(data[i])):\n",
    "          # if data[i][j]!=0:\n",
    "          #   first=data[i][j]\n",
    "          #   data[i]=data[i]/first+5\n",
    "          #   break\n",
    "\n",
    "        \n",
    "        mean_list.append(mean)\n",
    "        std_list.append(std)   \n",
    "    # return data,first\n",
    "    return data,mean_list,std_list\n",
    "\n",
    "def get_mask(data):\n",
    "    \"\"\"\n",
    "    data should in the form of pd.df\n",
    "    gen a tenor with 0 and 1 to represent missing data\n",
    "    \"\"\"\n",
    "    mask = ~data.isnan().values\n",
    " \n",
    "    mask_tensor = torch.tensor(mask, dtype=torch.float32)\n",
    "    \n",
    "    mask_tensor= mask_tensor.transpose(0,1)\n",
    "    return mask_tensor\n",
    "\n",
    "def mape(A,F,maskf_sub):\n",
    "  sum=0\n",
    "  length=0\n",
    "  for i in range(len(A)):\n",
    "   \n",
    "    if maskf_sub[i]!=0:\n",
    "      sum+=abs(A[i] - F[i]) / abs(A[i])\n",
    "      length+=1\n",
    "  if length>0:\n",
    "    return 100/length*sum\n",
    "  \n",
    "  return 0\n",
    "def smape(A, F,maskf_sub):\n",
    "  sum=0\n",
    "  length=0\n",
    "  for i in range(len(A)):\n",
    "    if maskf_sub[i]!=0:\n",
    "      sum+=2 * abs(F[i] - A[i]) / (abs(A[i]) + abs(F[i]))\n",
    "      length+=1\n",
    "  if length>0:\n",
    "\n",
    "    return 100/length * sum\n",
    "  return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_inputs(data, context_length, prediction_length):\n",
    "    num_days, num_products = data.shape\n",
    "    num_samples = num_days - context_length - prediction_length + 1\n",
    "   \n",
    "\n",
    "    samples = torch.zeros((num_samples, context_length,num_products))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        samples[i,:,:] = data[i:i+context_length]\n",
    "\n",
    "    return samples,num_samples\n",
    "def create_targets(data,context_length,prediction_length):\n",
    "    num_days, num_products = data.shape\n",
    "    num_samples = num_days - context_length - prediction_length + 1\n",
    "    \n",
    "\n",
    "    targets = torch.zeros((num_samples, prediction_length,num_products))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        targets[i, :,:] = data[i+context_length:i+prediction_length+context_length]\n",
    "\n",
    "    return targets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_train_val(data,prediction_period,batchs,context_length):\n",
    " \n",
    "    whole,m,std=normalize(data.iloc[:,1:])\n",
    "    whole=torch.tensor(whole.values)\n",
    "    # whole=whole.transpose(0,1)\n",
    "   \n",
    "    inputs,period=create_inputs(whole,context_length,prediction_period)\n",
    "    target=create_targets(whole,context_length,prediction_period)\n",
    "    inputs=inputs.reshape(period,1,200*context_length)\n",
    "    target=target.reshape(period,1,prediction_period*200)\n",
    "    # print(inputs.shape)\n",
    "    # train_input=inputs[:period-prediction_period].transpose(0,1)\n",
    "    # test_input=inputs[:period-prediction_period].transpose(0,1)\n",
    "    # train_target=target[:period-prediction_period].transpose(0,1)\n",
    "    # test_target=target[period-prediction_period:].transpose(0,1)\n",
    "    train_input=inputs[:period-prediction_period]\n",
    "    test_input=inputs[-1:]\n",
    "    train_target=target[:period-prediction_period]\n",
    "    test_target=target[-1:]\n",
    "    print(test_input.shape,test_target.shape)\n",
    "    \n",
    "    traindict={'target':train_target,'input':train_input}\n",
    "    testdict={'target':test_target,'input':test_input}\n",
    "    train=Dataset.from_dict(traindict)\n",
    "    train=train.with_format('torch')\n",
    "    test=Dataset.from_dict(testdict)\n",
    "    test=test.with_format('torch')\n",
    "    \n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=batchs, shuffle=False)\n",
    "    test_loader = DataLoader(test, batch_size=batchs, shuffle=False)\n",
    "    return train_loader, test_loader,m,std\n",
    "\n",
    "class S4Model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        d_input, \n",
    "        d_output=10, \n",
    "        d_model=256, \n",
    "        n_layers=4, \n",
    "        dropout=0.2,\n",
    "        prenorm=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.prenorm = prenorm\n",
    "\n",
    "        # Linear encoder (d_input = 1 for grayscale and 3 for RGB)\n",
    "        self.encoder = nn.Linear(d_input, d_model)\n",
    "\n",
    "        # Stack S4 layers as residual blocks\n",
    "        self.s4_layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.s4_layers.append(\n",
    "                S4.S4(\n",
    "                    d_model=d_model, \n",
    "                    l_max=1024, \n",
    "                    bidirectional=True,\n",
    "                    postact='glu',\n",
    "                    dropout=dropout, \n",
    "                    transposed=True,\n",
    "                )\n",
    "            )\n",
    "            self.norms.append(nn.LayerNorm(d_model))\n",
    "            self.dropouts.append(nn.Dropout2d(dropout))\n",
    "\n",
    "        # Linear decoder\n",
    "        self.decoder = nn.Linear(d_model, d_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input x is shape (B, L, d_input)\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)  # (B, L, d_input) -> (B, L, d_model)\n",
    "        \n",
    "        x = x.transpose(-1, -2)  # (B, L, d_model) -> (B, d_model, L)\n",
    "        for layer, norm, dropout in zip(self.s4_layers, self.norms, self.dropouts):\n",
    "            # Each iteration of this loop will map (B, d_model, L) -> (B, d_model, L)\n",
    "\n",
    "            z = x\n",
    "            if self.prenorm:\n",
    "                # Prenorm\n",
    "                z = norm(z.transpose(-1, -2)).transpose(-1, -2)\n",
    "            \n",
    "            # Apply S4 block: we ignore the state input and output\n",
    "            z, _ = layer(z)\n",
    "\n",
    "            # Dropout on the output of the S4 block\n",
    "            z = dropout(z)\n",
    "\n",
    "            # Residual connection\n",
    "            x = z + x\n",
    "\n",
    "            if not self.prenorm:\n",
    "                # Postnorm\n",
    "                x = norm(x.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "        x = x.transpose(-1, -2)\n",
    "\n",
    "        # Pooling: average pooling over the sequence length\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        # Decode the outputs\n",
    "        x = self.decoder(x)  # (B, d_model) -> (B, d_output)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch,train,ct,pt):\n",
    "    model = S4Model(\n",
    "    d_input=200*ct, \n",
    "    d_output=pt*200, \n",
    "    d_model=64, \n",
    "    n_layers=4, \n",
    "\n",
    "    dropout=0.1,\n",
    "    prenorm=False\n",
    "    )\n",
    "    device='cpu'\n",
    "    model = model.to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=0.001,)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epoch):\n",
    "        for ind,batch in enumerate(train):\n",
    "            optimizer.zero_grad()\n",
    "            target=batch['target']\n",
    "            inputs=batch['input']\n",
    "            target_mask = ~torch.isnan(target)\n",
    "            # target_mask = target_mask.view(target.shape[0],target.shape[1],target.shape[2])\n",
    "            valid_target = target[target_mask]\n",
    "            # input_mask=target_mask.reshape()\n",
    "            # valid_inputs = inputs[target_mask]\n",
    "        \n",
    "            \n",
    "            # inputs=Variable(inputs,requires_grad=True)\n",
    "            # input_mask = ~torch.isnan(inputs)\n",
    "            # input_mask=input_mask.reshape(inputs.shape[0],inputs.shape[1],inputs.shape[2])\n",
    "            # print(input_mask.shape)\n",
    "            # valid_inputs = inputs[input_mask]\n",
    "            # print(valid_inputs.shape)\n",
    "            inputs=inputs.nan_to_num()\n",
    "            inputs=Variable(inputs,requires_grad=True)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            # print(outputs)\n",
    "            output_mask=target_mask.reshape(outputs.shape[0],outputs.shape[1])\n",
    "            criterion = nn.MSELoss()\n",
    "            valid_outputs=outputs[output_mask]\n",
    "            # print(valid_outputs)\n",
    "            # break\n",
    "            loss =criterion(valid_outputs,valid_target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            print(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,test,pt):\n",
    "    pred=[]\n",
    "    for ind,batch in enumerate(test):\n",
    "        inputs=batch['input']\n",
    "        inputs=inputs.nan_to_num()\n",
    "        print(inputs,inputs.shape)\n",
    "        out=model(inputs)\n",
    "        out=out.reshape(pt,200)\n",
    "        out=out.T\n",
    "        pred=pred+list(out)\n",
    "        \n",
    "    return pred\n",
    "            \n",
    "def denormalize(data,mean,std):\n",
    "    for i in range(len(data)):\n",
    "        print(data[i],std[i],mean[i])\n",
    "        data[i]=data[i]*std[i]+mean[i]\n",
    "    return data       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S4_run(data,pred_length,batch_size,context_l,epoch):\n",
    "    train,test,m,std=split_train_val(data,pred_length,batch_size,context_l)\n",
    "    model=train_model(epoch,train,context_l,pred_length)\n",
    "    pred=predict(model,test,pred_length)\n",
    "    denormalize_pred=denormalize(pred,m,std)\n",
    "    return model,pred,denormalize_pred,test,m,std\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 400]) torch.Size([1, 1, 200])\n",
      "1.4655784368515015\n",
      "1.0363974571228027\n",
      "0.795599639415741\n",
      "0.8695045709609985\n",
      "0.8285287618637085\n",
      "0.6728562116622925\n",
      "0.5595833659172058\n",
      "0.475406676530838\n",
      "0.6038219332695007\n",
      "0.5538503527641296\n",
      "tensor([[[-1.3807,  0.0000, -2.2558, -2.7749, -2.3478, -2.0596, -2.4736,\n",
      "          -6.5312, -2.4400, -1.2093, -1.9307, -1.3097, -0.7255,  0.0000,\n",
      "          -1.6630,  0.3356, -2.3994, -0.9367, -1.4892, -1.2223, -0.4660,\n",
      "          -1.3072, -1.2659, -1.8598, -1.2002, -2.3777, -2.6416, -1.2747,\n",
      "          -2.2976, -2.4221, -1.4364, -2.1847, -2.5928, -2.0102,  2.3824,\n",
      "          -2.2012, -4.3677, -1.6630, -1.1870, -2.0778, -2.5532, -2.1227,\n",
      "          -1.6650, -3.8979, -1.0991, -0.5008, -1.2060,  1.9325, -1.4256,\n",
      "          -1.6206,  2.0791, -1.5203, -1.8614, -1.5339, -0.7087, -2.1707,\n",
      "          -0.4593, -2.2442, -1.7802, -1.7730, -2.3163, -2.6467, -1.5884,\n",
      "          -1.7526, -2.2285, -2.2102, -1.1118, -2.3826, -1.5347, -1.5440,\n",
      "          -1.4871, -1.5623, -2.0704, -1.3703, -2.2814, -1.6604, -1.8139,\n",
      "          -1.7303, -2.6145, -2.3412, -1.4296, -1.0957, -1.9807, -2.1669,\n",
      "          -1.8438, -1.7659, -2.4554, -1.8226, -0.5603, -2.1061, -2.4650,\n",
      "          -0.6701, -1.3854, -1.6726, -1.2054, -0.9364, -0.6551, -1.5731,\n",
      "          -2.1626, -0.7196, -1.3268, -1.5617, -2.0487, -1.0255, -1.6916,\n",
      "          -2.7469, -1.4277, -1.2845, -1.5217, -2.9209, -2.4602, -1.9472,\n",
      "           0.0000, -2.4364, -0.9025, -1.3252, -1.5792, -0.8801, -1.4849,\n",
      "          -1.7540, -1.5875, -0.0275,  3.5348,  0.8803, -1.7487, -2.5418,\n",
      "          -2.0545, -0.4072, -2.1300, -1.7646, -1.6113, -1.3560, -1.0575,\n",
      "          -1.9969, -1.8457, -2.3066, -0.7970,  1.9325, -1.3282, -1.1950,\n",
      "          -1.6105,  0.0000, -1.8133, -1.7153, -2.0427, -1.4495, -0.6843,\n",
      "           0.0000, -1.2500, -1.1930,  1.0087, -1.0501, -1.7089, -2.7749,\n",
      "          -1.3845, -0.7125, -1.7339, -0.1531, -2.5260, -2.4593, -1.8557,\n",
      "          -3.1439, -2.2560, -1.5156, -1.3525, -1.3381, -2.3099, -1.3501,\n",
      "          -1.4475, -1.6707, -1.4985, -2.0963, -1.6500, -1.4961, -1.2214,\n",
      "          -2.7244, -2.2340, -2.0992, -1.4399, -1.6275, -2.4650, -0.1668,\n",
      "          -0.7743,  0.0000, -1.9775, -2.8773, -2.8707,  0.0000, -1.8260,\n",
      "          -2.0117, -2.3014, -2.3163, -0.4880,  0.0000, -0.1563, -0.5924,\n",
      "          -5.2248,  3.4600,  0.9728,  0.0000, -1.0184, -1.4947, -2.0200,\n",
      "          -1.9702, -1.6348, -2.1045, -2.4632, -6.2491, -2.4617, -1.2284,\n",
      "          -1.9182, -1.2707, -0.7860, -1.5119, -1.6616,  0.6746, -2.3879,\n",
      "          -0.7969, -1.4934, -1.1918, -0.4382, -1.1481, -1.2505, -1.8147,\n",
      "          -1.1238, -2.3368, -2.5896, -1.1473, -2.3512, -1.0562, -1.1308,\n",
      "          -2.1830, -2.5870, -2.0047,  2.1721, -2.2033, -4.3555, -1.6616,\n",
      "          -1.2142, -2.0880, -0.7384, -2.0858, -1.6661, -3.8912, -1.0826,\n",
      "          -0.4037, -1.1918,  1.7284, -1.4173, -1.5721,  2.0928, -1.7068,\n",
      "          -1.7703, -1.4155, -0.6875, -2.2077, -0.4563, -2.1999, -1.8087,\n",
      "          -1.7466, -2.2849, -2.6327, -1.5878, -1.7638, -2.1102, -0.8608,\n",
      "          -0.8893, -2.3792, -1.5298, -1.5394, -1.4390, -0.9491, -2.0237,\n",
      "          -1.3194, -2.0871, -1.6728, -1.8171, -1.7083, -2.5940, -2.3068,\n",
      "          -1.4054, -2.1593, -2.0093, -2.1694, -1.8621, -1.7075, -2.3158,\n",
      "          -1.7998, -0.7801, -2.0830, -2.4223, -0.6579, -1.4030, -1.6709,\n",
      "          -1.1283, -0.9296, -0.6169, -1.5859, -2.1239, -0.7171, -1.3146,\n",
      "          -1.5699, -0.4852, -0.8369, -1.6901, -2.6765, -1.4223, -1.2448,\n",
      "          -1.4412, -2.8916, -2.3570, -1.9378, -1.7120, -1.2453, -0.8656,\n",
      "          -0.8416, -1.5695, -0.1394, -1.4843, -0.7193, -0.7823, -0.0263,\n",
      "           3.1841,  0.8398, -1.6798, -2.5597, -2.0375, -0.3869, -2.1710,\n",
      "          -1.4487, -1.6202, -1.3568, -0.9708, -1.9185, -1.8304, -1.8402,\n",
      "          -0.7194,  1.7284, -1.2787, -1.1822, -1.7002, -0.1109, -1.8033,\n",
      "          -1.7740, -2.0364, -1.4337, -0.7428,  0.0000, -1.1299, -1.1184,\n",
      "           0.8535, -1.0314, -1.5351, -1.9702, -1.4060, -0.5755, -1.7319,\n",
      "          -0.1006, -2.5135, -2.4313, -1.2050, -3.1244, -1.5794, -1.2646,\n",
      "          -1.3625, -1.3391, -2.2068, -1.3306, -1.4501, -1.6616, -1.5016,\n",
      "          -1.8885, -1.6132, -1.4842, -0.5669, -2.7303, -2.2009, -1.4794,\n",
      "          -1.4342, -1.5438, -2.4223, -0.1206, -0.5033, -1.4953, -1.9983,\n",
      "          -2.8694, -2.8189, -1.7120, -1.0927, -2.0810, -2.3593, -2.2849,\n",
      "          -0.2717, -1.4953, -0.1280, -0.5693, -5.2390,  3.2164,  0.8149,\n",
      "          -1.5013]]]) torch.Size([1, 1, 400])\n",
      "tensor([-0.6258], grad_fn=<UnbindBackward0>) 22.566338194292367 54.660836036\n",
      "tensor([-1.2889], grad_fn=<UnbindBackward0>) 21.352693682121906 71.59599817895273\n",
      "tensor([-0.8657], grad_fn=<UnbindBackward0>) 15.31383884856238 46.5442520624942\n",
      "tensor([-1.3539], grad_fn=<UnbindBackward0>) 10.513081911778668 33.70292012136068\n",
      "tensor([-1.2484], grad_fn=<UnbindBackward0>) 10.982356564803199 50.82534551553106\n",
      "tensor([-1.1450], grad_fn=<UnbindBackward0>) 14.698812830526599 34.944050536168085\n",
      "tensor([-1.4009], grad_fn=<UnbindBackward0>) 10.493594970680324 30.787306447587937\n",
      "tensor([-1.1791], grad_fn=<UnbindBackward0>) 0.8862187721802829 0.08809326210609945\n",
      "tensor([-1.6340], grad_fn=<UnbindBackward0>) 14.248636550049314 38.55614075761523\n",
      "tensor([-0.7518], grad_fn=<UnbindBackward0>) 262.49632385764136 1104.4498448810755\n",
      "tensor([-0.6774], grad_fn=<UnbindBackward0>) 12.18852233023381 58.42064347979275\n",
      "tensor([-1.1273], grad_fn=<UnbindBackward0>) 17.730894021658784 149.1290710984456\n",
      "tensor([-0.2574], grad_fn=<UnbindBackward0>) 103.6610553176997 392.6060791139896\n",
      "tensor([-1.2505], grad_fn=<UnbindBackward0>) 20.97140193198374 71.63655011983889\n",
      "tensor([-1.0517], grad_fn=<UnbindBackward0>) 12.258903970249484 49.575400147012985\n",
      "tensor([-0.8176], grad_fn=<UnbindBackward0>) 13.92103561011443 39.35825250155078\n",
      "tensor([-1.8076], grad_fn=<UnbindBackward0>) 11.275746424417642 31.905509165365363\n",
      "tensor([-0.6608], grad_fn=<UnbindBackward0>) 12.874735493777337 44.10011888110944\n",
      "tensor([-1.0753], grad_fn=<UnbindBackward0>) 180.58220384509085 374.8202898098446\n",
      "tensor([-0.3443], grad_fn=<UnbindBackward0>) 6.557432218716752 71.46565662797929\n",
      "tensor([-0.4899], grad_fn=<UnbindBackward0>) 11.904777743474341 47.2172560963819\n",
      "tensor([-0.9476], grad_fn=<UnbindBackward0>) 17.978003389033184 67.23025596350001\n",
      "tensor([-1.2851], grad_fn=<UnbindBackward0>) 20.572146613326428 36.13322466782383\n",
      "tensor([-0.7838], grad_fn=<UnbindBackward0>) 32.999309615784725 335.8188848498965\n",
      "tensor([-1.0208], grad_fn=<UnbindBackward0>) 61.69495314728856 418.6360799947754\n",
      "tensor([-1.2016], grad_fn=<UnbindBackward0>) 56.462559606005634 194.2206637460662\n",
      "tensor([-1.6509], grad_fn=<UnbindBackward0>) 78.8255054753434 412.5091401097179\n",
      "tensor([-0.5543], grad_fn=<UnbindBackward0>) 10.753875366594718 39.98767697381948\n",
      "tensor([-1.0219], grad_fn=<UnbindBackward0>) 214.5288296135992 677.3909686060919\n",
      "tensor([-1.1091], grad_fn=<UnbindBackward0>) 13.84411025417587 38.49228204784877\n",
      "tensor([-0.8251], grad_fn=<UnbindBackward0>) 14.003879244808527 43.44535774479877\n",
      "tensor([-0.7866], grad_fn=<UnbindBackward0>) 13.330933074123312 90.23990825660964\n",
      "tensor([-1.4326], grad_fn=<UnbindBackward0>) 99.91207960891168 299.727216335005\n",
      "tensor([-0.8095], grad_fn=<UnbindBackward0>) 10.67947443142101 52.45714945440415\n",
      "tensor([1.4940], grad_fn=<UnbindBackward0>) 39.885949663559686 338.51109777720205\n",
      "tensor([-1.7147], grad_fn=<UnbindBackward0>) 18.230848478402418 96.8274475984456\n",
      "tensor([-0.1312], grad_fn=<UnbindBackward0>) 0.8241392297744722 0.1495664887760814\n",
      "tensor([-0.9946], grad_fn=<UnbindBackward0>) 12.258903970249484 49.575400147012985\n",
      "tensor([-0.5009], grad_fn=<UnbindBackward0>) 13.814345188121113 39.06029387304075\n",
      "tensor([-1.4628], grad_fn=<UnbindBackward0>) 13.748509848669741 33.947127212606304\n",
      "tensor([-1.3756], grad_fn=<UnbindBackward0>) 10.001117996343385 28.934591399012504\n",
      "tensor([-1.4162], grad_fn=<UnbindBackward0>) 16.79726593848824 149.06789069487982\n",
      "tensor([-1.2889], grad_fn=<UnbindBackward0>) 59.104091648193574 229.22039281865287\n",
      "tensor([-1.5275], grad_fn=<UnbindBackward0>) 5.392788946088198 80.60004882378854\n",
      "tensor([-0.6785], grad_fn=<UnbindBackward0>) 21.415042036525104 43.359372624346925\n",
      "tensor([-0.3792], grad_fn=<UnbindBackward0>) 46.17687017750058 211.71372516062178\n",
      "tensor([-1.3174], grad_fn=<UnbindBackward0>) 11.775769824381731 19.53327190316062\n",
      "tensor([1.0770], grad_fn=<UnbindBackward0>) 41.601052596820736 358.5226114420063\n",
      "tensor([-1.0536], grad_fn=<UnbindBackward0>) 284.6768185555935 765.5128170207254\n",
      "tensor([-0.9216], grad_fn=<UnbindBackward0>) 19.468187147184672 148.93189942528736\n",
      "tensor([1.7141], grad_fn=<UnbindBackward0>) 510.7144733410428 1113.1922246220302\n",
      "tensor([-1.0817], grad_fn=<UnbindBackward0>) 13.29478887595757 48.91155773576459\n",
      "tensor([-0.9246], grad_fn=<UnbindBackward0>) 25.104526328820796 70.44327794594594\n",
      "tensor([-0.8639], grad_fn=<UnbindBackward0>) 19.305511378722414 53.32735115056878\n",
      "tensor([-0.8513], grad_fn=<UnbindBackward0>) 20.41042202568688 71.5162395893417\n",
      "tensor([-1.0579], grad_fn=<UnbindBackward0>) 7.296961342529376 34.1392268029382\n",
      "tensor([0.0722], grad_fn=<UnbindBackward0>) 67.26403504239106 61.36176964165\n",
      "tensor([-1.2188], grad_fn=<UnbindBackward0>) 226.0869460876621 1687.375\n",
      "tensor([-0.9937], grad_fn=<UnbindBackward0>) 192.72061177369744 1855.5817282665278\n",
      "tensor([-1.3552], grad_fn=<UnbindBackward0>) 33.620586318426845 142.6157335787013\n",
      "tensor([-1.3946], grad_fn=<UnbindBackward0>) 35.043400289532485 133.369924319171\n",
      "tensor([-1.1712], grad_fn=<UnbindBackward0>) 14.270413552553654 49.499505195966286\n",
      "tensor([-0.9907], grad_fn=<UnbindBackward0>) 17.497271315244777 55.33990596682218\n",
      "tensor([-1.0211], grad_fn=<UnbindBackward0>) 25.077938232739786 72.1317519530303\n",
      "tensor([-0.7951], grad_fn=<UnbindBackward0>) 13.437490963294167 37.905174642601736\n",
      "tensor([-0.6932], grad_fn=<UnbindBackward0>) 11.878913315220553 51.224878210655326\n",
      "tensor([0.0270], grad_fn=<UnbindBackward0>) 22.02471226791566 48.69752420661539\n",
      "tensor([-1.6264], grad_fn=<UnbindBackward0>) 11.688452811289027 32.75866303026513\n",
      "tensor([-1.0714], grad_fn=<UnbindBackward0>) 42.46484850641138 225.5440011761658\n",
      "tensor([-0.8230], grad_fn=<UnbindBackward0>) 45.89392781399238 234.74549583722137\n",
      "tensor([-0.8671], grad_fn=<UnbindBackward0>) 38.39815089180564 329.0329948911917\n",
      "tensor([-1.0725], grad_fn=<UnbindBackward0>) 14.921662486942385 41.01192744741495\n",
      "tensor([-1.4752], grad_fn=<UnbindBackward0>) 5.874725610690426 54.87237785544041\n",
      "tensor([-1.0068], grad_fn=<UnbindBackward0>) 24.690041000461544 199.948868373057\n",
      "tensor([-0.9103], grad_fn=<UnbindBackward0>) 13.020607230874372 45.864765075604836\n",
      "tensor([-1.2141], grad_fn=<UnbindBackward0>) 24.285601667526443 69.7447491424962\n",
      "tensor([-1.2063], grad_fn=<UnbindBackward0>) 71.96363532447948 226.43470230673577\n",
      "tensor([-1.0856], grad_fn=<UnbindBackward0>) 0.6366608836849282 2.031629846390471\n",
      "tensor([-1.5121], grad_fn=<UnbindBackward0>) 13.358299773350986 52.178213532258056\n",
      "tensor([-1.4854], grad_fn=<UnbindBackward0>) 68.1691723046781 270.9160856424871\n",
      "tensor([-0.6227], grad_fn=<UnbindBackward0>) 31.805588354490645 85.30324223068948\n",
      "tensor([-1.2670], grad_fn=<UnbindBackward0>) 10.47429446795701 38.87700930225239\n",
      "tensor([-0.8317], grad_fn=<UnbindBackward0>) 15.452960521971477 126.69345798328109\n",
      "tensor([-1.3127], grad_fn=<UnbindBackward0>) 11.790269886635546 55.42827882\n",
      "tensor([-1.0787], grad_fn=<UnbindBackward0>) 22.9339169359621 127.48582467098446\n",
      "tensor([-0.7990], grad_fn=<UnbindBackward0>) 3.0065462581359546 13.178739260507246\n",
      "tensor([-1.5732], grad_fn=<UnbindBackward0>) 10.027073669425135 27.83035918323662\n",
      "tensor([-1.0611], grad_fn=<UnbindBackward0>) 3.0474644231880244 13.092187019523562\n",
      "tensor([-0.3014], grad_fn=<UnbindBackward0>) 13.326542014979296 30.596274983466095\n",
      "tensor([-1.5208], grad_fn=<UnbindBackward0>) 60.35893356790974 192.40899253649025\n",
      "tensor([-1.4015], grad_fn=<UnbindBackward0>) 10.783667835798882 31.111684720560284\n",
      "tensor([-0.6530], grad_fn=<UnbindBackward0>) 24.918910818195126 34.71804749174312\n",
      "tensor([-0.7149], grad_fn=<UnbindBackward0>) 4.544492783936888 20.136115523670757\n",
      "tensor([-0.8382], grad_fn=<UnbindBackward0>) 15.519751910643842 56.24682872213582\n",
      "tensor([-0.8022], grad_fn=<UnbindBackward0>) 920.8589948513476 6250.005729166666\n",
      "tensor([-0.5273], grad_fn=<UnbindBackward0>) 24.704036834796874 59.60467011807733\n",
      "tensor([-0.3645], grad_fn=<UnbindBackward0>) 45.695980917194284 63.93854364727104\n",
      "tensor([-1.1120], grad_fn=<UnbindBackward0>) 24.328004380538474 72.13149441010101\n",
      "tensor([-1.1117], grad_fn=<UnbindBackward0>) 59.829310200233856 192.10414812278876\n",
      "tensor([0.0352], grad_fn=<UnbindBackward0>) 54.89586073040232 51.365329261645094\n",
      "tensor([-0.5602], grad_fn=<UnbindBackward0>) 11.399883202317618 33.473265077324974\n",
      "tensor([-0.8784], grad_fn=<UnbindBackward0>) 24.336046669361036 72.13453694997473\n",
      "tensor([-0.9662], grad_fn=<UnbindBackward0>) 11.685076083637679 27.339543260097745\n",
      "tensor([-0.5098], grad_fn=<UnbindBackward0>) 35.99827505260367 56.36676477625001\n",
      "tensor([-0.8832], grad_fn=<UnbindBackward0>) 31.654686119018265 127.20529058031087\n",
      "tensor([-1.2153], grad_fn=<UnbindBackward0>) 13.722532360069273 164.78008998432603\n",
      "tensor([-1.1347], grad_fn=<UnbindBackward0>) 81.90047561543449 458.96594264248705\n",
      "tensor([-0.8003], grad_fn=<UnbindBackward0>) 133.68173463697585 1157.4003008342022\n",
      "tensor([-0.4426], grad_fn=<UnbindBackward0>) 14.943564218636041 180.83007431034483\n",
      "tensor([-0.9832], grad_fn=<UnbindBackward0>) 0.6141343550467733 2.1188183429777316\n",
      "tensor([-1.5798], grad_fn=<UnbindBackward0>) 10.465147078843048 29.435864706984926\n",
      "tensor([-1.5208], grad_fn=<UnbindBackward0>) 14.986479608411637 33.98107454017008\n",
      "tensor([-1.0072], grad_fn=<UnbindBackward0>) 24.75847022189759 71.80681761760242\n",
      "tensor([-0.9270], grad_fn=<UnbindBackward0>) 13.038443692138587 36.67734458642463\n",
      "tensor([-1.5025], grad_fn=<UnbindBackward0>) 21.943001756630977 126.64178550731452\n",
      "tensor([-1.0224], grad_fn=<UnbindBackward0>) 9.884338346195015 39.448463822668\n",
      "tensor([-1.0300], grad_fn=<UnbindBackward0>) 62.823117955721884 268.1697581243523\n",
      "tensor([-1.4686], grad_fn=<UnbindBackward0>) 9.261488649156522 35.45114915037519\n",
      "tensor([-1.2140], grad_fn=<UnbindBackward0>) 36.18260005518195 138.19787514626557\n",
      "tensor([-1.4455], grad_fn=<UnbindBackward0>) 9.800400093030644 28.349438440279638\n",
      "tensor([-0.5334], grad_fn=<UnbindBackward0>) 18.807798276854147 50.66397256988494\n",
      "tensor([0.0597], grad_fn=<UnbindBackward0>) 8095.342036189161 237.56060740870436\n",
      "tensor([1.6234], grad_fn=<UnbindBackward0>) 28.032318699939776 419.74555050061053\n",
      "tensor([0.6855], grad_fn=<UnbindBackward0>) 24.690380927689084 102.26555141757106\n",
      "tensor([-0.0124], grad_fn=<UnbindBackward0>) 20.99580986580748 113.12601012279794\n",
      "tensor([-1.4862], grad_fn=<UnbindBackward0>) 13.439100526523374 37.899398214007\n",
      "tensor([-1.0817], grad_fn=<UnbindBackward0>) 25.23997408266608 69.58648505626599\n",
      "tensor([0.0534], grad_fn=<UnbindBackward0>) 103.840729452343 67.2765507365\n",
      "tensor([-0.8052], grad_fn=<UnbindBackward0>) 0.4879968115617251 -0.01054794589091831\n",
      "tensor([-1.1970], grad_fn=<UnbindBackward0>) 13.987481862436105 44.72298829321608\n",
      "tensor([-0.9657], grad_fn=<UnbindBackward0>) 24.731446818584903 72.12058599696664\n",
      "tensor([-0.6001], grad_fn=<UnbindBackward0>) 24.448827875036457 86.39333919170986\n",
      "tensor([-0.6017], grad_fn=<UnbindBackward0>) 28.375294338986375 56.547214755\n",
      "tensor([-0.8581], grad_fn=<UnbindBackward0>) 21.22737551545051 121.48331796865205\n",
      "tensor([-1.2504], grad_fn=<UnbindBackward0>) 0.5031715383646359 2.1781973696530295\n",
      "tensor([-0.9438], grad_fn=<UnbindBackward0>) 15.608175005943485 54.001771449172935\n",
      "tensor([-0.3401], grad_fn=<UnbindBackward0>) 53.467852493571776 68.314749917985\n",
      "tensor([1.3384], grad_fn=<UnbindBackward0>) 41.601052596820736 358.5226114420063\n",
      "tensor([-1.1548], grad_fn=<UnbindBackward0>) 88.32121913589563 704.0364390979781\n",
      "tensor([-0.4641], grad_fn=<UnbindBackward0>) 46.49414643616984 136.90882389184952\n",
      "tensor([-1.4334], grad_fn=<UnbindBackward0>) 8.802956042942133 38.707088757723994\n",
      "tensor([-0.0528], grad_fn=<UnbindBackward0>) 321.7617435892944 78.05305856869653\n",
      "tensor([-0.9100], grad_fn=<UnbindBackward0>) 63.91443478931279 204.68568826711618\n",
      "tensor([-0.9583], grad_fn=<UnbindBackward0>) 4.597340467360258 21.08563445542537\n",
      "tensor([-0.8672], grad_fn=<UnbindBackward0>) 25.49723132729594 71.59359410374935\n",
      "tensor([-0.4991], grad_fn=<UnbindBackward0>) 15.751845684408282 61.4968997476684\n",
      "tensor([-0.4097], grad_fn=<UnbindBackward0>) 45.704715544030634 296.73725053\n",
      "tensor([-0.8399], grad_fn=<UnbindBackward0>) 9.403896660293084 121.11756517756046\n",
      "tensor([-1.0233], grad_fn=<UnbindBackward0>) 63.867967617321035 427.9555348589342\n",
      "tensor([-0.5138], grad_fn=<UnbindBackward0>) 30.874336035584765 339.6020245924765\n",
      "tensor([0.6541], grad_fn=<UnbindBackward0>) 23.366750870222532 166.1519388756477\n",
      "tensor([-0.9429], grad_fn=<UnbindBackward0>) 43.438000404656364 91.25946481421647\n",
      "tensor([-0.5006], grad_fn=<UnbindBackward0>) 18.6423153247888 47.918504579810026\n",
      "tensor([-1.4119], grad_fn=<UnbindBackward0>) 10.513081911778668 33.70292012136068\n",
      "tensor([-0.7489], grad_fn=<UnbindBackward0>) 4.6588306349556925 24.45027468079673\n",
      "tensor([-0.0981], grad_fn=<UnbindBackward0>) 54.3520063484691 60.36285239123685\n",
      "tensor([-1.1212], grad_fn=<UnbindBackward0>) 31.011129275011637 156.7807829377916\n",
      "tensor([0.2883], grad_fn=<UnbindBackward0>) 169.45861902612623 43.95074865655\n",
      "tensor([-1.3233], grad_fn=<UnbindBackward0>) 2.1255965218178248 7.462048147357514\n",
      "tensor([-1.3325], grad_fn=<UnbindBackward0>) 10.015990945504115 27.84197097512012\n",
      "tensor([-0.8108], grad_fn=<UnbindBackward0>) 12.232811765789211 41.64091832530681\n",
      "tensor([-1.1467], grad_fn=<UnbindBackward0>) 12.685150664782268 231.1038971894273\n",
      "tensor([-1.0898], grad_fn=<UnbindBackward0>) 18.032896814712565 66.48199134449999\n",
      "tensor([-0.8839], grad_fn=<UnbindBackward0>) 28.327926497104976 62.42289438886102\n",
      "tensor([-0.5700], grad_fn=<UnbindBackward0>) 28.855923684213316 195.53059592746115\n",
      "tensor([-0.6649], grad_fn=<UnbindBackward0>) 28.67889316987417 110.31729921577848\n",
      "tensor([-1.5235], grad_fn=<UnbindBackward0>) 94.87685591891326 261.12149466984926\n",
      "tensor([-1.0590], grad_fn=<UnbindBackward0>) 44.61508826553626 279.79149980829015\n",
      "tensor([-1.1677], grad_fn=<UnbindBackward0>) 21.762838384560865 42.55147920523316\n",
      "tensor([-1.0789], grad_fn=<UnbindBackward0>) 331.9606674352521 956.1653799792747\n",
      "tensor([-1.2578], grad_fn=<UnbindBackward0>) 186.8912902049576 395.1868313471503\n",
      "tensor([-0.8726], grad_fn=<UnbindBackward0>) 19.969093317701862 67.5614282195\n",
      "tensor([-1.0888], grad_fn=<UnbindBackward0>) 15.113508719642175 126.46583789393938\n",
      "tensor([-0.8522], grad_fn=<UnbindBackward0>) 181.08126487445693 456.4845353523316\n",
      "tensor([-0.8540], grad_fn=<UnbindBackward0>) 19.432565266956487 38.62538209927996\n",
      "tensor([-1.8059], grad_fn=<UnbindBackward0>) 11.79404340794413 35.731587373015074\n",
      "tensor([-1.5592], grad_fn=<UnbindBackward0>) 12.062088210263164 31.467082392496245\n",
      "tensor([-0.7139], grad_fn=<UnbindBackward0>) 15.762930197551128 49.08983745858723\n",
      "tensor([-1.0048], grad_fn=<UnbindBackward0>) 142.41158269560333 458.0644127668394\n",
      "tensor([-0.9966], grad_fn=<UnbindBackward0>) 12.126391232856122 149.44655330371145\n",
      "tensor([-1.5977], grad_fn=<UnbindBackward0>) 10.783667835798882 31.111684720560284\n",
      "tensor([0.0201], grad_fn=<UnbindBackward0>) 125.00597791595047 47.01956020772171\n",
      "tensor([0.1828], grad_fn=<UnbindBackward0>) 15.944765334319664 101.03435169896373\n",
      "tensor([-1.1102], grad_fn=<UnbindBackward0>) 19.766279629096143 71.08707993457472\n",
      "tensor([-0.8075], grad_fn=<UnbindBackward0>) 12.781500591436174 119.06520687305701\n",
      "tensor([-1.5784], grad_fn=<UnbindBackward0>) 10.04940648491243 32.60541731366834\n",
      "tensor([-1.0534], grad_fn=<UnbindBackward0>) 14.084429472842206 54.70278402868741\n",
      "tensor([-1.2472], grad_fn=<UnbindBackward0>) 24.75847022189759 71.80681761760242\n",
      "tensor([-0.5335], grad_fn=<UnbindBackward0>) 12.135910414625464 40.160534412340006\n",
      "tensor([-1.1883], grad_fn=<UnbindBackward0>) 21.792796907288576 63.661502501113574\n",
      "tensor([-1.2923], grad_fn=<UnbindBackward0>) 11.927748211822243 32.09080406748374\n",
      "tensor([-1.1738], grad_fn=<UnbindBackward0>) 35.043400289532485 133.369924319171\n",
      "tensor([-0.0159], grad_fn=<UnbindBackward0>) 10.772395700545054 24.037181973181955\n",
      "tensor([-1.3631], grad_fn=<UnbindBackward0>) 19.766279629096143 71.08707993457472\n",
      "tensor([-0.8614], grad_fn=<UnbindBackward0>) 9.016779119344731 51.14913728369906\n",
      "tensor([-0.6396], grad_fn=<UnbindBackward0>) 37.88794485652135 137.81456004075235\n",
      "tensor([-0.4415], grad_fn=<UnbindBackward0>) 0.7046300804202236 0.011542173484247992\n",
      "tensor([1.5458], grad_fn=<UnbindBackward0>) 44.674721044934984 36.21709987016632\n",
      "tensor([0.3918], grad_fn=<UnbindBackward0>) 5.003875001720749 -6.487606743940819\n",
      "tensor([-0.7847], grad_fn=<UnbindBackward0>) 20.14910241682425 71.26887678057372\n"
     ]
    }
   ],
   "source": [
    "get=S4_run(data,1,50,2,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mape(A,F,maskf_sub):\n",
    "  sum=0\n",
    "  length=0\n",
    "  for i in range(len(A)):\n",
    "    # print(A[i],\"A\",maskf_sub[i],\"ma\")\n",
    "    if not torch.isnan(A[i]):\n",
    "    # if maskf_sub[i]!=0:\n",
    "      sum+=abs(A[i] - F[i]) / abs(A[i])\n",
    "      length+=1\n",
    "  if length>0:\n",
    "    return 100/length*sum\n",
    "  \n",
    "  return 0\n",
    "def smape(A, F,maskf_sub):\n",
    "  sum=0\n",
    "  length=0\n",
    "  for i in range(len(A)):\n",
    "    if not torch.isnan(A[i]):\n",
    "    # if maskf_sub[i]!=0:\n",
    "      sum+=2 * abs(F[i] - A[i]) / (abs(A[i]) + abs(F[i]))\n",
    "      length+=1\n",
    "  if length>0:\n",
    "\n",
    "    return 100/length * sum\n",
    "  return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False,  True,  True])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0417]) 22.566338194292367 54.660836036\n",
      "tensor([-1.5064]) 21.352693682121906 71.59599817895273\n",
      "tensor([-3.0452]) 15.31383884856238 46.5442520624942\n",
      "tensor([-2.1719]) 10.513081911778668 33.70292012136068\n",
      "tensor([-2.2360]) 10.982356564803199 50.82534551553106\n",
      "tensor([-2.0331]) 14.698812830526599 34.944050536168085\n",
      "tensor([-2.4536]) 10.493594970680324 30.787306447587937\n",
      "tensor([-6.2491]) 0.8862187721802829 0.08809326210609945\n",
      "tensor([-2.3508]) 14.248636550049314 38.55614075761523\n",
      "tensor([-1.2246]) 262.49632385764136 1104.4498448810755\n",
      "tensor([-1.9424]) 12.18852233023381 58.42064347979275\n",
      "tensor([-1.2680]) 17.730894021658784 149.1290710984456\n",
      "tensor([-0.7283]) 103.6610553176997 392.6060791139896\n",
      "tensor([-1.5229]) 20.97140193198374 71.63655011983889\n",
      "tensor([-1.6660]) 12.258903970249484 49.575400147012985\n",
      "tensor([-1.5479]) 13.92103561011443 39.35825250155078\n",
      "tensor([-2.4305]) 11.275746424417642 31.905509165365363\n",
      "tensor([-0.2563]) 12.874735493777337 44.10011888110944\n",
      "tensor([-1.5644]) 180.58220384509085 374.8202898098446\n",
      "tensor([-1.1871]) 6.557432218716752 71.46565662797929\n",
      "tensor([-2.1182]) 11.904777743474341 47.2172560963819\n",
      "tensor([-1.6871]) 17.978003389033184 67.23025596350001\n",
      "tensor([-1.2116]) 20.572146613326428 36.13322466782383\n",
      "tensor([-1.8459]) 32.999309615784725 335.8188848498965\n",
      "tensor([-1.1530]) 61.69495314728856 418.6360799947754\n",
      "tensor([-2.4257]) 56.462559606005634 194.2206637460662\n",
      "tensor([-2.5102]) 78.8255054753434 412.5091401097179\n",
      "tensor([-2.3124]) 10.753875366594718 39.98767697381948\n",
      "tensor([-2.3381]) 214.5288296135992 677.3909686060919\n",
      "tensor([-2.3766]) 13.84411025417587 38.49228204784877\n",
      "tensor([-3.3866]) 14.003879244808527 43.44535774479877\n",
      "tensor([-2.1690]) 13.330933074123312 90.23990825660964\n",
      "tensor([-2.4783]) 99.91207960891168 299.727216335005\n",
      "tensor([-2.0017]) 10.67947443142101 52.45714945440415\n",
      "tensor([2.2513]) 39.885949663559686 338.51109777720205\n",
      "tensor([-2.3367]) 18.230848478402418 96.8274475984456\n",
      "tensor([-4.2099]) 0.8241392297744722 0.1495664887760814\n",
      "tensor([-1.6660]) 12.258903970249484 49.575400147012985\n",
      "tensor([-1.2440]) 13.814345188121113 39.06029387304075\n",
      "tensor([-1.9767]) 13.748509848669741 33.947127212606304\n",
      "tensor([-2.4502]) 10.001117996343385 28.934591399012504\n",
      "tensor([-1.9543]) 16.79726593848824 149.06789069487982\n",
      "tensor([-1.7732]) 59.104091648193574 229.22039281865287\n",
      "tensor([-3.9124]) 5.392788946088198 80.60004882378854\n",
      "tensor([-1.0496]) 21.415042036525104 43.359372624346925\n",
      "tensor([-0.2396]) 46.17687017750058 211.71372516062178\n",
      "tensor([-1.1560]) 11.775769824381731 19.53327190316062\n",
      "tensor([1.8049]) 41.601052596820736 358.5226114420063\n",
      "tensor([-1.4712]) 284.6768185555935 765.5128170207254\n",
      "tensor([-1.5787]) 19.468187147184672 148.93189942528736\n",
      "tensor([2.0928]) 510.7144733410428 1113.1922246220302\n",
      "tensor([-2.2709]) 13.29478887595757 48.91155773576459\n",
      "tensor([-1.9862]) 25.104526328820796 70.44327794594594\n",
      "tensor([-1.6963]) 19.305511378722414 53.32735115056878\n",
      "tensor([-0.5673]) 20.41042202568688 71.5162395893417\n",
      "tensor([-2.1816]) 7.296961342529376 34.1392268029382\n",
      "tensor([-0.4127]) 67.26403504239106 61.36176964165\n",
      "tensor([-2.1778]) 226.0869460876621 1687.375\n",
      "tensor([-1.8295]) 192.72061177369744 1855.5817282665278\n",
      "tensor([nan]) 33.620586318426845 142.6157335787013\n",
      "tensor([-2.2433]) 35.043400289532485 133.369924319171\n",
      "tensor([-2.7490]) 14.270413552553654 49.499505195966286\n",
      "tensor([-1.6314]) 17.497271315244777 55.33990596682218\n",
      "tensor([-1.7973]) 25.077938232739786 72.1317519530303\n",
      "tensor([-2.5254]) 13.437490963294167 37.905174642601736\n",
      "tensor([-2.1109]) 11.878913315220553 51.224878210655326\n",
      "tensor([-1.2798]) 22.02471226791566 48.69752420661539\n",
      "tensor([-2.3920]) 11.688452811289027 32.75866303026513\n",
      "tensor([-1.5216]) 42.46484850641138 225.5440011761658\n",
      "tensor([-1.5318]) 45.89392781399238 234.74549583722137\n",
      "tensor([-1.4406]) 38.39815089180564 329.0329948911917\n",
      "tensor([-1.2741]) 14.921662486942385 41.01192744741495\n",
      "tensor([-2.0179]) 5.874725610690426 54.87237785544041\n",
      "tensor([-1.2848]) 24.690041000461544 199.948868373057\n",
      "tensor([-2.5402]) 13.020607230874372 45.864765075604836\n",
      "tensor([-1.6312]) 24.285601667526443 69.7447491424962\n",
      "tensor([-1.9484]) 71.96363532447948 226.43470230673577\n",
      "tensor([-1.8120]) 0.6366608836849282 2.031629846390471\n",
      "tensor([nan]) 13.358299773350986 52.178213532258056\n",
      "tensor([-2.2612]) 68.1691723046781 270.9160856424871\n",
      "tensor([-1.4382]) 31.805588354490645 85.30324223068948\n",
      "tensor([-2.5087]) 10.47429446795701 38.87700930225239\n",
      "tensor([-2.0264]) 15.452960521971477 126.69345798328109\n",
      "tensor([-2.4773]) 11.790269886635546 55.42827882\n",
      "tensor([-2.0160]) 22.9339169359621 127.48582467098446\n",
      "tensor([-1.7302]) 3.0065462581359546 13.178739260507246\n",
      "tensor([-2.3457]) 10.027073669425135 27.83035918323662\n",
      "tensor([-1.8529]) 3.0474644231880244 13.092187019523562\n",
      "tensor([-0.3516]) 13.326542014979296 30.596274983466095\n",
      "tensor([-2.1937]) 60.35893356790974 192.40899253649025\n",
      "tensor([-2.3871]) 10.783667835798882 31.111684720560284\n",
      "tensor([-0.6102]) 24.918910818195126 34.71804749174312\n",
      "tensor([-1.4559]) 4.544492783936888 20.136115523670757\n",
      "tensor([-1.7013]) 15.519751910643842 56.24682872213582\n",
      "tensor([-1.1582]) 920.8589948513476 6250.005729166666\n",
      "tensor([-0.8970]) 24.704036834796874 59.60467011807733\n",
      "tensor([-0.5634]) 45.695980917194284 63.93854364727104\n",
      "tensor([-1.6258]) 24.328004380538474 72.13149441010101\n",
      "tensor([-2.2079]) 59.829310200233856 192.10414812278876\n",
      "tensor([-0.7023]) 54.89586073040232 51.365329261645094\n",
      "tensor([-1.3457]) 11.399883202317618 33.473265077324974\n",
      "tensor([-1.6537]) 24.336046669361036 72.13453694997473\n",
      "tensor([-1.9606]) 11.685076083637679 27.339543260097745\n",
      "tensor([-0.4141]) 35.99827505260367 56.36676477625001\n",
      "tensor([-1.7615]) 31.654686119018265 127.20529058031087\n",
      "tensor([-2.7518]) 13.722532360069273 164.78008998432603\n",
      "tensor([-1.4132]) 81.90047561543449 458.96594264248705\n",
      "tensor([-1.2357]) 133.68173463697585 1157.4003008342022\n",
      "tensor([-1.5269]) 14.943564218636041 180.83007431034483\n",
      "tensor([-2.9730]) 0.6141343550467733 2.1188183429777316\n",
      "tensor([-2.3761]) 10.465147078843048 29.435864706984926\n",
      "tensor([-1.9485]) 14.986479608411637 33.98107454017008\n",
      "tensor([-1.7936]) 24.75847022189759 71.80681761760242\n",
      "tensor([-2.4449]) 13.038443692138587 36.67734458642463\n",
      "tensor([-0.6562]) 21.943001756630977 126.64178550731452\n",
      "tensor([-1.2574]) 9.884338346195015 39.448463822668\n",
      "tensor([-1.6207]) 62.823117955721884 268.1697581243523\n",
      "tensor([-1.9760]) 9.261488649156522 35.45114915037519\n",
      "tensor([-1.4857]) 36.18260005518195 138.19787514626557\n",
      "tensor([-2.0376]) 9.800400093030644 28.349438440279638\n",
      "tensor([-1.0982]) 18.807798276854147 50.66397256988494\n",
      "tensor([-0.0249]) 8095.342036189161 237.56060740870436\n",
      "tensor([3.3161]) 28.032318699939776 419.74555050061053\n",
      "tensor([0.9208]) 24.690380927689084 102.26555141757106\n",
      "tensor([-1.7590]) 20.99580986580748 113.12601012279794\n",
      "tensor([-2.4480]) 13.439100526523374 37.899398214007\n",
      "tensor([-2.1948]) 25.23997408266608 69.58648505626599\n",
      "tensor([-0.3493]) 103.840729452343 67.2765507365\n",
      "tensor([-2.7038]) 0.4879968115617251 -0.01054794589091831\n",
      "tensor([-4.8946]) 13.987481862436105 44.72298829321608\n",
      "tensor([-1.7096]) 24.731446818584903 72.12058599696664\n",
      "tensor([-1.3813]) 24.448827875036457 86.39333919170986\n",
      "tensor([-1.0688]) 28.375294338986375 56.547214755\n",
      "tensor([-1.8145]) 21.22737551545051 121.48331796865205\n",
      "tensor([-1.7660]) 0.5031715383646359 2.1781973696530295\n",
      "tensor([-1.0963]) 15.608175005943485 54.001771449172935\n",
      "tensor([-0.7832]) 53.467852493571776 68.314749917985\n",
      "tensor([1.8049]) 41.601052596820736 358.5226114420063\n",
      "tensor([-1.2132]) 88.32121913589563 704.0364390979781\n",
      "tensor([-1.2155]) 46.49414643616984 136.90882389184952\n",
      "tensor([-2.6988]) 8.802956042942133 38.707088757723994\n",
      "tensor([-0.1111]) 321.7617435892944 78.05305856869653\n",
      "tensor([-1.9078]) 63.91443478931279 204.68568826711618\n",
      "tensor([-1.7435]) 4.597340467360258 21.08563445542537\n",
      "tensor([-2.0957]) 25.49723132729594 71.59359410374935\n",
      "tensor([-1.4326]) 15.751845684408282 61.4968997476684\n",
      "tensor([-1.1624]) 45.704715544030634 296.73725053\n",
      "tensor([nan]) 9.403896660293084 121.11756517756046\n",
      "tensor([-1.1735]) 63.867967617321035 427.9555348589342\n",
      "tensor([-1.1978]) 30.874336035584765 339.6020245924765\n",
      "tensor([0.9187]) 23.366750870222532 166.1519388756477\n",
      "tensor([-0.9939]) 43.438000404656364 91.25946481421647\n",
      "tensor([-1.2246]) 18.6423153247888 47.918504579810026\n",
      "tensor([-2.1719]) 10.513081911778668 33.70292012136068\n",
      "tensor([-1.4618]) 4.6588306349556925 24.45027468079673\n",
      "tensor([-0.4543]) 54.3520063484691 60.36285239123685\n",
      "tensor([-1.7380]) 31.011129275011637 156.7807829377916\n",
      "tensor([-0.1381]) 169.45861902612623 43.95074865655\n",
      "tensor([-2.4559]) 2.1255965218178248 7.462048147357514\n",
      "tensor([-2.3494]) 10.015990945504115 27.84197097512012\n",
      "tensor([-1.6056]) 12.232811765789211 41.64091832530681\n",
      "tensor([-3.0916]) 12.685150664782268 231.1038971894273\n",
      "tensor([-1.6404]) 18.032896814712565 66.48199134449999\n",
      "tensor([-1.1799]) 28.327926497104976 62.42289438886102\n",
      "tensor([-1.3568]) 28.855923684213316 195.53059592746115\n",
      "tensor([-1.3672]) 28.67889316987417 110.31729921577848\n",
      "tensor([-2.2236]) 94.87685591891326 261.12149466984926\n",
      "tensor([-1.3823]) 44.61508826553626 279.79149980829015\n",
      "tensor([-1.5073]) 21.762838384560865 42.55147920523316\n",
      "tensor([-1.7421]) 331.9606674352521 956.1653799792747\n",
      "tensor([-1.5709]) 186.8912902049576 395.1868313471503\n",
      "tensor([-2.0593]) 19.969093317701862 67.5614282195\n",
      "tensor([-1.4823]) 15.113508719642175 126.46583789393938\n",
      "tensor([-1.5138]) 181.08126487445693 456.4845353523316\n",
      "tensor([-1.4900]) 19.432565266956487 38.62538209927996\n",
      "tensor([-2.6252]) 11.79404340794413 35.731587373015074\n",
      "tensor([-2.1926]) 12.062088210263164 31.467082392496245\n",
      "tensor([-0.6528]) 15.762930197551128 49.08983745858723\n",
      "tensor([-1.4765]) 142.41158269560333 458.0644127668394\n",
      "tensor([-1.5897]) 12.126391232856122 149.44655330371145\n",
      "tensor([-2.3871]) 10.783667835798882 31.111684720560284\n",
      "tensor([-0.2321]) 125.00597791595047 47.01956020772171\n",
      "tensor([-0.5280]) 15.944765334319664 101.03435169896373\n",
      "tensor([-1.5004]) 19.766279629096143 71.08707993457472\n",
      "tensor([-2.1076]) 12.781500591436174 119.06520687305701\n",
      "tensor([-2.7639]) 10.04940648491243 32.60541731366834\n",
      "tensor([-2.8920]) 14.084429472842206 54.70278402868741\n",
      "tensor([-1.7936]) 24.75847022189759 71.80681761760242\n",
      "tensor([-1.6159]) 12.135910414625464 40.160534412340006\n",
      "tensor([-4.6181]) 21.792796907288576 63.661502501113574\n",
      "tensor([-2.3031]) 11.927748211822243 32.09080406748374\n",
      "tensor([-2.2433]) 35.043400289532485 133.369924319171\n",
      "tensor([-1.9046]) 10.772395700545054 24.037181973181955\n",
      "tensor([-1.5004]) 19.766279629096143 71.08707993457472\n",
      "tensor([-0.1835]) 9.016779119344731 51.14913728369906\n",
      "tensor([-0.4383]) 37.88794485652135 137.81456004075235\n",
      "tensor([-5.0829]) 0.7046300804202236 0.011542173484247992\n",
      "tensor([nan]) 44.674721044934984 36.21709987016632\n",
      "tensor([0.5111]) 5.003875001720749 -6.487606743940819\n",
      "tensor([-1.5087]) 20.14910241682425 71.26887678057372\n"
     ]
    }
   ],
   "source": [
    "smpl=[]\n",
    "mpl=[]\n",
    "m=get[4]\n",
    "std=get[5]\n",
    "act=next(iter(get[3]))\n",
    "act=(act['target']).reshape(1,200)\n",
    "act=act.T\n",
    "deno_pred=get[2]\n",
    "act=denormalize(act,m,std)\n",
    "act_mask=(~torch.isnan(act))\n",
    "act_mask=act_mask.reshape(200*1)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(200):\n",
    "\n",
    "    mp=mape(act[i],deno_pred[i],act_mask)\n",
    "    smp=smape(act[i],deno_pred[i],act_mask)\n",
    "    \n",
    "    smpl.append(float(smp))\n",
    "    mpl.append(float(mp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([40.5384], grad_fn=<CopySlices>),\n",
       " tensor([44.0737], grad_fn=<CopySlices>),\n",
       " tensor([33.2871], grad_fn=<CopySlices>),\n",
       " tensor([19.4688], grad_fn=<CopySlices>),\n",
       " tensor([37.1147], grad_fn=<CopySlices>),\n",
       " tensor([18.1134], grad_fn=<CopySlices>),\n",
       " tensor([16.0869], grad_fn=<CopySlices>),\n",
       " tensor([-0.9569], grad_fn=<CopySlices>),\n",
       " tensor([15.2743], grad_fn=<CopySlices>),\n",
       " tensor([907.1180], grad_fn=<CopySlices>),\n",
       " tensor([50.1646], grad_fn=<CopySlices>),\n",
       " tensor([129.1405], grad_fn=<CopySlices>),\n",
       " tensor([365.9274], grad_fn=<CopySlices>),\n",
       " tensor([45.4108], grad_fn=<CopySlices>),\n",
       " tensor([36.6822], grad_fn=<CopySlices>),\n",
       " tensor([27.9767], grad_fn=<CopySlices>),\n",
       " tensor([11.5234], grad_fn=<CopySlices>),\n",
       " tensor([35.5931], grad_fn=<CopySlices>),\n",
       " tensor([180.6326], grad_fn=<CopySlices>),\n",
       " tensor([69.2079], grad_fn=<CopySlices>),\n",
       " tensor([41.3855], grad_fn=<CopySlices>),\n",
       " tensor([50.1941], grad_fn=<CopySlices>),\n",
       " tensor([9.6958], grad_fn=<CopySlices>),\n",
       " tensor([309.9542], grad_fn=<CopySlices>),\n",
       " tensor([355.6567], grad_fn=<CopySlices>),\n",
       " tensor([126.3760], grad_fn=<CopySlices>),\n",
       " tensor([282.3785], grad_fn=<CopySlices>),\n",
       " tensor([34.0265], grad_fn=<CopySlices>),\n",
       " tensor([458.1545], grad_fn=<CopySlices>),\n",
       " tensor([23.1372], grad_fn=<CopySlices>),\n",
       " tensor([31.8912], grad_fn=<CopySlices>),\n",
       " tensor([79.7536], grad_fn=<CopySlices>),\n",
       " tensor([156.5897], grad_fn=<CopySlices>),\n",
       " tensor([43.8126], grad_fn=<CopySlices>),\n",
       " tensor([398.0992], grad_fn=<CopySlices>),\n",
       " tensor([65.5671], grad_fn=<CopySlices>),\n",
       " tensor([0.0414], grad_fn=<CopySlices>),\n",
       " tensor([37.3822], grad_fn=<CopySlices>),\n",
       " tensor([32.1411], grad_fn=<CopySlices>),\n",
       " tensor([13.8361], grad_fn=<CopySlices>),\n",
       " tensor([15.1774], grad_fn=<CopySlices>),\n",
       " tensor([125.2793], grad_fn=<CopySlices>),\n",
       " tensor([153.0389], grad_fn=<CopySlices>),\n",
       " tensor([72.3627], grad_fn=<CopySlices>),\n",
       " tensor([28.8294], grad_fn=<CopySlices>),\n",
       " tensor([194.2018], grad_fn=<CopySlices>),\n",
       " tensor([4.0198], grad_fn=<CopySlices>),\n",
       " tensor([403.3258], grad_fn=<CopySlices>),\n",
       " tensor([465.5658], grad_fn=<CopySlices>),\n",
       " tensor([130.9907], grad_fn=<CopySlices>),\n",
       " tensor([1988.5930], grad_fn=<CopySlices>),\n",
       " tensor([34.5309], grad_fn=<CopySlices>),\n",
       " tensor([47.2319], grad_fn=<CopySlices>),\n",
       " tensor([36.6488], grad_fn=<CopySlices>),\n",
       " tensor([54.1403], grad_fn=<CopySlices>),\n",
       " tensor([26.4194], grad_fn=<CopySlices>),\n",
       " tensor([66.2196], grad_fn=<CopySlices>),\n",
       " tensor([1411.8137], grad_fn=<CopySlices>),\n",
       " tensor([1664.0671], grad_fn=<CopySlices>),\n",
       " tensor([97.0526], grad_fn=<CopySlices>),\n",
       " tensor([84.4967], grad_fn=<CopySlices>),\n",
       " tensor([32.7854], grad_fn=<CopySlices>),\n",
       " tensor([38.0050], grad_fn=<CopySlices>),\n",
       " tensor([46.5256], grad_fn=<CopySlices>),\n",
       " tensor([27.2216], grad_fn=<CopySlices>),\n",
       " tensor([42.9909], grad_fn=<CopySlices>),\n",
       " tensor([49.2918], grad_fn=<CopySlices>),\n",
       " tensor([13.7481], grad_fn=<CopySlices>),\n",
       " tensor([180.0457], grad_fn=<CopySlices>),\n",
       " tensor([196.9725], grad_fn=<CopySlices>),\n",
       " tensor([295.7366], grad_fn=<CopySlices>),\n",
       " tensor([25.0088], grad_fn=<CopySlices>),\n",
       " tensor([46.2062], grad_fn=<CopySlices>),\n",
       " tensor([175.0900], grad_fn=<CopySlices>),\n",
       " tensor([34.0120], grad_fn=<CopySlices>),\n",
       " tensor([40.2587], grad_fn=<CopySlices>),\n",
       " tensor([139.6219], grad_fn=<CopySlices>),\n",
       " tensor([1.3405], grad_fn=<CopySlices>),\n",
       " tensor([31.9793], grad_fn=<CopySlices>),\n",
       " tensor([169.6597], grad_fn=<CopySlices>),\n",
       " tensor([65.4977], grad_fn=<CopySlices>),\n",
       " tensor([25.6062], grad_fn=<CopySlices>),\n",
       " tensor([113.8409], grad_fn=<CopySlices>),\n",
       " tensor([39.9510], grad_fn=<CopySlices>),\n",
       " tensor([102.7479], grad_fn=<CopySlices>),\n",
       " tensor([10.7764], grad_fn=<CopySlices>),\n",
       " tensor([12.0554], grad_fn=<CopySlices>),\n",
       " tensor([9.8585], grad_fn=<CopySlices>),\n",
       " tensor([26.5790], grad_fn=<CopySlices>),\n",
       " tensor([100.6161], grad_fn=<CopySlices>),\n",
       " tensor([15.9983], grad_fn=<CopySlices>),\n",
       " tensor([18.4448], grad_fn=<CopySlices>),\n",
       " tensor([16.8870], grad_fn=<CopySlices>),\n",
       " tensor([43.2382], grad_fn=<CopySlices>),\n",
       " tensor([5511.2549], grad_fn=<CopySlices>),\n",
       " tensor([46.5783], grad_fn=<CopySlices>),\n",
       " tensor([47.2843], grad_fn=<CopySlices>),\n",
       " tensor([45.0793], grad_fn=<CopySlices>),\n",
       " tensor([125.5893], grad_fn=<CopySlices>),\n",
       " tensor([53.2963], grad_fn=<CopySlices>),\n",
       " tensor([27.0868], grad_fn=<CopySlices>),\n",
       " tensor([50.7571], grad_fn=<CopySlices>),\n",
       " tensor([16.0494], grad_fn=<CopySlices>),\n",
       " tensor([38.0139], grad_fn=<CopySlices>),\n",
       " tensor([99.2465], grad_fn=<CopySlices>),\n",
       " tensor([148.1026], grad_fn=<CopySlices>),\n",
       " tensor([366.0301], grad_fn=<CopySlices>),\n",
       " tensor([1050.4197], grad_fn=<CopySlices>),\n",
       " tensor([174.2163], grad_fn=<CopySlices>),\n",
       " tensor([1.5150], grad_fn=<CopySlices>),\n",
       " tensor([12.9026], grad_fn=<CopySlices>),\n",
       " tensor([11.1901], grad_fn=<CopySlices>),\n",
       " tensor([46.8690], grad_fn=<CopySlices>),\n",
       " tensor([24.5903], grad_fn=<CopySlices>),\n",
       " tensor([93.6724], grad_fn=<CopySlices>),\n",
       " tensor([29.3427], grad_fn=<CopySlices>),\n",
       " tensor([203.4589], grad_fn=<CopySlices>),\n",
       " tensor([21.8500], grad_fn=<CopySlices>),\n",
       " tensor([94.2731], grad_fn=<CopySlices>),\n",
       " tensor([14.1829], grad_fn=<CopySlices>),\n",
       " tensor([40.6319], grad_fn=<CopySlices>),\n",
       " tensor([720.5689], grad_fn=<CopySlices>),\n",
       " tensor([465.2527], grad_fn=<CopySlices>),\n",
       " tensor([119.1900], grad_fn=<CopySlices>),\n",
       " tensor([112.8652], grad_fn=<CopySlices>),\n",
       " tensor([17.9262], grad_fn=<CopySlices>),\n",
       " tensor([42.2832], grad_fn=<CopySlices>),\n",
       " tensor([72.8165], grad_fn=<CopySlices>),\n",
       " tensor([-0.4035], grad_fn=<CopySlices>),\n",
       " tensor([27.9799], grad_fn=<CopySlices>),\n",
       " tensor([48.2385], grad_fn=<CopySlices>),\n",
       " tensor([71.7213], grad_fn=<CopySlices>),\n",
       " tensor([39.4735], grad_fn=<CopySlices>),\n",
       " tensor([103.2684], grad_fn=<CopySlices>),\n",
       " tensor([1.5490], grad_fn=<CopySlices>),\n",
       " tensor([39.2703], grad_fn=<CopySlices>),\n",
       " tensor([50.1296], grad_fn=<CopySlices>),\n",
       " tensor([414.2024], grad_fn=<CopySlices>),\n",
       " tensor([602.0427], grad_fn=<CopySlices>),\n",
       " tensor([115.3294], grad_fn=<CopySlices>),\n",
       " tensor([26.0893], grad_fn=<CopySlices>),\n",
       " tensor([61.0637], grad_fn=<CopySlices>),\n",
       " tensor([146.5239], grad_fn=<CopySlices>),\n",
       " tensor([16.6799], grad_fn=<CopySlices>),\n",
       " tensor([49.4832], grad_fn=<CopySlices>),\n",
       " tensor([53.6349], grad_fn=<CopySlices>),\n",
       " tensor([278.0123], grad_fn=<CopySlices>),\n",
       " tensor([113.2189], grad_fn=<CopySlices>),\n",
       " tensor([362.6018], grad_fn=<CopySlices>),\n",
       " tensor([323.7392], grad_fn=<CopySlices>),\n",
       " tensor([181.4350], grad_fn=<CopySlices>),\n",
       " tensor([50.3026], grad_fn=<CopySlices>),\n",
       " tensor([38.5856], grad_fn=<CopySlices>),\n",
       " tensor([18.8590], grad_fn=<CopySlices>),\n",
       " tensor([20.9614], grad_fn=<CopySlices>),\n",
       " tensor([55.0335], grad_fn=<CopySlices>),\n",
       " tensor([122.0117], grad_fn=<CopySlices>),\n",
       " tensor([92.8097], grad_fn=<CopySlices>),\n",
       " tensor([4.6492], grad_fn=<CopySlices>),\n",
       " tensor([14.4957], grad_fn=<CopySlices>),\n",
       " tensor([31.7226], grad_fn=<CopySlices>),\n",
       " tensor([216.5573], grad_fn=<CopySlices>),\n",
       " tensor([46.8291], grad_fn=<CopySlices>),\n",
       " tensor([37.3847], grad_fn=<CopySlices>),\n",
       " tensor([179.0820], grad_fn=<CopySlices>),\n",
       " tensor([91.2482], grad_fn=<CopySlices>),\n",
       " tensor([116.5772], grad_fn=<CopySlices>),\n",
       " tensor([232.5420], grad_fn=<CopySlices>),\n",
       " tensor([17.1391], grad_fn=<CopySlices>),\n",
       " tensor([598.0238], grad_fn=<CopySlices>),\n",
       " tensor([160.1078], grad_fn=<CopySlices>),\n",
       " tensor([50.1357], grad_fn=<CopySlices>),\n",
       " tensor([110.0098], grad_fn=<CopySlices>),\n",
       " tensor([302.1719], grad_fn=<CopySlices>),\n",
       " tensor([22.0299], grad_fn=<CopySlices>),\n",
       " tensor([14.4325], grad_fn=<CopySlices>),\n",
       " tensor([12.6595], grad_fn=<CopySlices>),\n",
       " tensor([37.8369], grad_fn=<CopySlices>),\n",
       " tensor([314.9681], grad_fn=<CopySlices>),\n",
       " tensor([137.3619], grad_fn=<CopySlices>),\n",
       " tensor([13.8821], grad_fn=<CopySlices>),\n",
       " tensor([49.5279], grad_fn=<CopySlices>),\n",
       " tensor([103.9491], grad_fn=<CopySlices>),\n",
       " tensor([49.1423], grad_fn=<CopySlices>),\n",
       " tensor([108.7437], grad_fn=<CopySlices>),\n",
       " tensor([16.7433], grad_fn=<CopySlices>),\n",
       " tensor([39.8656], grad_fn=<CopySlices>),\n",
       " tensor([40.9279], grad_fn=<CopySlices>),\n",
       " tensor([33.6860], grad_fn=<CopySlices>),\n",
       " tensor([37.7642], grad_fn=<CopySlices>),\n",
       " tensor([16.6764], grad_fn=<CopySlices>),\n",
       " tensor([92.2365], grad_fn=<CopySlices>),\n",
       " tensor([23.8663], grad_fn=<CopySlices>),\n",
       " tensor([44.1437], grad_fn=<CopySlices>),\n",
       " tensor([43.3820], grad_fn=<CopySlices>),\n",
       " tensor([113.5829], grad_fn=<CopySlices>),\n",
       " tensor([-0.2996], grad_fn=<CopySlices>),\n",
       " tensor([105.2733], grad_fn=<CopySlices>),\n",
       " tensor([-4.5271], grad_fn=<CopySlices>),\n",
       " tensor([55.4571], grad_fn=<CopySlices>)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(deno_pred)):\n",
    "    for j in range(len(deno_pred[i])):\n",
    "        deno_pred[i][j]=float(deno_pred[i][j])\n",
    "deno_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred=[]\n",
    "for i in range(1):\n",
    "    new_pred.append([])\n",
    "    for j in range(200):\n",
    "        new_pred[i].append(float(deno_pred[j][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act=act.transpose(0,1)\n",
    "act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3829,     nan, -2.3504,  ...,     nan,  0.7469,     nan],\n",
       "        [-1.8033, -1.4076, -3.9960,  ...,  3.6882,  0.8189, -1.4243],\n",
       "        [-1.2896, -1.4015, -2.2819,  ...,  3.7455,  0.8489, -1.4094],\n",
       "        ...,\n",
       "        [-1.3807,     nan, -2.2558,  ...,  3.4600,  0.9728,     nan],\n",
       "        [-1.0184, -1.4947, -2.0200,  ...,  3.2164,  0.8149, -1.5013],\n",
       "        [-1.0417, -1.5064, -3.0452,  ...,     nan,  0.5111, -1.5087]])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# act=act.T\n",
    "result= pd.DataFrame({'S4_mape':mpl,'S4_smape':smpl})\n",
    "result.to_csv('D:/timeseries/result/temp_2.csv')\n",
    "res2= pd.DataFrame({'name':data.columns[1:],'day1/13_pred':act[0], 'day1/1_actu':new_pred[0]\n",
    "                       })\n",
    "res2.to_csv('D:/timeseries/result/temp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
