{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerForPrediction\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset, DatasetDict\n",
    "from gluonts.transform import AddTimeFeatures\n",
    "from gluonts.time_feature import time_features_from_frequency_str\n",
    "from gluonts.time_feature import get_lags_for_frequency\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('./data/data_6.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(sel,names):\n",
    "  \n",
    "  datamain=sel.query(\"SYMBOL=='%s'\"%(names[0]))\n",
    "  datamain=datamain[[\"DATE\",\"PRICE\"]]\n",
    "  datamain.drop_duplicates(subset=[\"DATE\"], keep='first', inplace=True)\n",
    "  datamain=datamain.sort_values(by=\"DATE\")\n",
    "  s=names[0]+\"_price\"\n",
    "  s2=names[0]+\"_size\"\n",
    "  # datamain[\"DATE\"]=pd.to_datetime(datamain[\"DATE\"])\n",
    "  datamain=datamain.rename(columns={\"PRICE\":s})\n",
    "  # datamain[s] = pd.to_numeric(datamain[\"PRICE\"])\n",
    "  # datamain[s2] = pd.to_numeric(datamain[\"SIZE\"])\n",
    "\n",
    "\n",
    "  for name in names:\n",
    "    if name==names[0]:\n",
    "      continue\n",
    "    data=sel.query(\"SYMBOL=='%s'\"%name)\n",
    "\n",
    "    data=data[[\"DATE\",\"PRICE\"]]\n",
    "    data.drop_duplicates(subset=[\"DATE\"], keep='first', inplace=True)\n",
    "    \n",
    "    # data[\"PRICE\"]=pd.to_datetime(data[\"PRICE\"])\n",
    "    # data[\"Close_\"] = pd.to_numeric(data[\"Close_\"])\n",
    " \n",
    "    data=data.rename(columns={\"PRICE\": \"%s_price\"%name})\n",
    "\n",
    "\n",
    "    datamain=pd.merge(datamain,data,on=\"DATE\", how=\"outer\")\n",
    "  return datamain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=list(set(data[\"SYMBOL\"]))\n",
    "data=transform_data(data,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(A,F,maskf_sub):\n",
    "  sum=0\n",
    "  length=0\n",
    "  for i in range(len(A)):\n",
    "   \n",
    "    if maskf_sub[i]!=0:\n",
    "      sum+=abs(A[i] - F[i]) / abs(A[i])\n",
    "      length+=1\n",
    "  if length>0:\n",
    "    return 100/length*sum\n",
    "  \n",
    "  return 0\n",
    "def smape(A, F,maskf_sub):\n",
    "  sum=0\n",
    "  length=0\n",
    "  for i in range(len(A)):\n",
    "    if maskf_sub[i]!=0:\n",
    "      sum+=2 * np.abs(F[i] - A[i]) / (np.abs(A[i]) + np.abs(F[i]))\n",
    "      length+=1\n",
    "  if length>0:\n",
    "\n",
    "    return 100/length * sum\n",
    "  return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(data):\n",
    "    \"\"\"\n",
    "    data should in the form of pd.df\n",
    "    gen a tenor with 0 and 1 to represent missing data\n",
    "    \"\"\"\n",
    "    mask = ~data.isna().values\n",
    " \n",
    "    mask_tensor = torch.tensor(mask, dtype=torch.float32)\n",
    "    \n",
    "    mask_tensor= mask_tensor.transpose(0,1)\n",
    "    return mask_tensor\n",
    "\n",
    "def get_time_feature(data):\n",
    "    \"\"\"\n",
    "    data should in form of pd.df\n",
    "    \"\"\"\n",
    "\n",
    "    ind=pd.PeriodIndex(data=data['DATE'],freq='D')\n",
    "    time_feature=ind.dayofyear.astype(float).values - 1\n",
    "    return time_feature\n",
    "\n",
    "def get_static_feature(inputsize):\n",
    "    no=torch.arange(1,inputsize+1,1)\n",
    "    no=no.unsqueeze(1)\n",
    "    no=no.to(torch.long)\n",
    "    return no\n",
    "\n",
    "def normalize(data):\n",
    "    mean_list=[]\n",
    "    std_list=[]\n",
    "    for i in data.columns:\n",
    "        mean=data[i].mean()\n",
    "        # mean=0\n",
    "        std=data[i].std()\n",
    "        # std=1\n",
    "        data[i]=(data[i]-mean)/std\n",
    "        mean_list.append(mean)\n",
    "        std_list.append(std)   \n",
    "    return data,mean_list,std_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(data,period,prediction_period,inputs,batchs,context_length):\n",
    "    \n",
    "    whole,mean_list,std_list=normalize(data.iloc[:,1:])\n",
    "\n",
    "    time_feature=get_time_feature(data)\n",
    "    past=torch.tensor([[time_feature[:period-prediction_period]]]*inputs)\n",
    "    past=past.transpose(1,2)\n",
    "    future=torch.tensor([[time_feature[period-prediction_period:period]]]*inputs)\n",
    "    future=future.transpose(1,2)\n",
    "\n",
    "    real=(torch.zeros((inputs,1))).to(torch.float32)\n",
    "\n",
    "    static=get_static_feature(inputs)\n",
    "\n",
    "    mask=get_mask(whole)\n",
    "    maskf=mask[:,period-prediction_period:]\n",
    "    maskp=mask[:,:period-prediction_period]\n",
    "   \n",
    "   \n",
    "    \n",
    "    whole=whole.fillna(0)\n",
    "    whole=torch.tensor(whole.values)\n",
    "    input=whole[:period-prediction_period].transpose(0,1)\n",
    "    target=whole[period-prediction_period:].transpose(0,1)\n",
    "\n",
    "    traindict={'target':target,'input':input,'past':past,'future':future,'maskp':maskp,'maskf':maskf,'sta':static,'real':real}\n",
    "    train=Dataset.from_dict(traindict)\n",
    "    train=train.with_format('torch')\n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=batchs, shuffle=False)\n",
    "    lags_sequence = get_lags_for_frequency('1D')\n",
    "    lags_sequence[15]=period-context_length-prediction_period\n",
    "\n",
    "\n",
    "    prediction_length = prediction_period\n",
    "    \n",
    "    input_size = 1\n",
    "    config = TimeSeriesTransformerConfig(\n",
    "        prediction_length=prediction_length,\n",
    "        context_length=context_length,\n",
    "        input_size=input_size,\n",
    "        encoder_layers=4,\n",
    "        decoder_layers=4,\n",
    "        d_model=22,\n",
    "        num_static_categorical_features= 1,\n",
    "        num_static_real_features= 1,\n",
    "        num_time_features=1,\n",
    "        cardinality=[inputs+1],\n",
    "        lags_sequence=lags_sequence[:16]\n",
    "    \n",
    "        \n",
    "        \n",
    "    )\n",
    "    model = TimeSeriesTransformerForPrediction(config)\n",
    "    \n",
    "    learning_rate = 0.001  \n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=6e-4, betas=(0.9, 0.95), weight_decay=1e-1)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(20):\n",
    "        for ind,batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            # print(batch,ind,\"ind\")\n",
    "            outputs = model(\n",
    "                static_categorical_features=batch[\"sta\"]\n",
    "                if config.num_static_categorical_features > 0\n",
    "                else None,\n",
    "                static_real_features=batch[\"real\"]\n",
    "                if config.num_static_real_features > 0\n",
    "                else None,\n",
    "                past_time_features=batch[\"past\"],\n",
    "                past_values=batch[\"input\"],\n",
    "                future_time_features=batch[\"future\"],\n",
    "                future_values=batch[\"target\"],\n",
    "                past_observed_mask=batch[\"maskp\"],\n",
    "                future_observed_mask=batch[\"maskf\"],\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            print(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "    forecasts = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        outputs = model.generate(\n",
    "            static_categorical_features=batch[\"sta\"]\n",
    "            if config.num_static_categorical_features > 0\n",
    "            else None,\n",
    "            static_real_features=batch[\"real\"]\n",
    "            if config.num_static_real_features > 0\n",
    "            else None,\n",
    "            past_time_features=batch[\"past\"],\n",
    "            past_values=batch[\"input\"],\n",
    "            future_time_features=batch[\"future\"],\n",
    "            past_observed_mask=batch[\"maskp\"],\n",
    "        )\n",
    "        forecasts.append(outputs.sequences.cpu().numpy())\n",
    "    forecasts = np.vstack(forecasts)\n",
    "    foremean=np.mean(forecasts,1)\n",
    "    test=train['target']\n",
    "\n",
    "    mapel=[]\n",
    "    smapel=[]\n",
    "\n",
    "    for i in range(inputs):\n",
    "        foremean[i]=foremean[i]*std_list[i]+mean_list[i]\n",
    "        test[i]=test[i]*std_list[i]+mean_list[i]\n",
    "        m=mape(foremean[i],test[i],maskf[i])\n",
    "        mapel.append(float(m))\n",
    "        sm=smape(foremean[i],test[i],maskf[i])\n",
    "        smapel.append(float(sm))\n",
    "    return foremean,test,mapel,smapel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.464726448059082\n",
      "1.4424943923950195\n",
      "1.4190622568130493\n",
      "1.3977991342544556\n",
      "1.378961205482483\n",
      "1.3624372482299805\n",
      "1.3479242324829102\n",
      "1.33517324924469\n",
      "1.3241077661514282\n",
      "1.3147393465042114\n"
     ]
    }
   ],
   "source": [
    "# get=transformer(data,data.shape[0],7,3,30,14)\n",
    "# get=transformer(data,data.shape[0],3,3,30,6)\n",
    "get=transformer(data,data.shape[0],1,3,30,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res= pd.DataFrame({'trans_mape':get[2],'trans_smape':get[3]})\n",
    "# res.to_csv('D:/timeseries/result/temp2.csv')\n",
    "\n",
    "# # result= pd.DataFrame({'name':data.columns[1:],'day1_pred':get[0][:,0], 'day1_actu':get[1][:,0]\n",
    "#                 #    })\n",
    "# result= pd.DataFrame({'name':data.columns[1:],'day1/7_pred':get[0][:,0], 'day1/7_actu':get[1][:,0], 'day2/7_pred':get[0][:,1], 'day2/7_actu':get[1][:,1],\n",
    "#                        'day3/7_pred':get[0][:,2], 'day3/7_actu':get[1][:,2], 'day4/7_pred':get[0][:,3], 'day4/7_actu':get[1][:,3], \n",
    "#                        'day5/7_pred':get[0][:,4], 'day5/7_actu':get[1][:,4], 'day6/7_pred':get[0][:,5], 'day6/7_actu':get[1][:,5],\n",
    "#                        'day7/7_pred':get[0][:,6], 'day7/7_actu':get[1][:,6]\n",
    "#                        })\n",
    "# result.to_csv('D:/timeseries/result/temp.csv')\n",
    "\n",
    "res= pd.DataFrame({'trans_mape':get[2],'trans_smape':get[3]})\n",
    "res.to_csv('D:/timeseries/result/temp2.csv')\n",
    "\n",
    "# result= pd.DataFrame({'name':data.columns[1:],'day1_pred':get[0][:,0], 'day1_actu':get[1][:,0]\n",
    "                #    })\n",
    "result= pd.DataFrame({'name':data.columns[1:],'day1/1_pred':get[0][:,0], 'day1/1_actu':get[1][:,0]\n",
    "                       })\n",
    "result.to_csv('D:/timeseries/result/temp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
